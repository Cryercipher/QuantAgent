import asyncio
from llama_index.core.agent import ReActAgent
from llama_index.core.memory import ChatMemoryBuffer
from llama_index.core import Settings

from core.llm_factory import ModelFactory
from tools.market_data import MarketDataManager
from tools.quant_analysis import QuantAnalyzer
from tools.knowledge_base import FinancialKnowledgeBase
from prompts.system_prompts import AGENT_SYSTEM_PROMPT, AGENT_CONTEXT_INJECTION
from utils.logger import get_logger

logger = get_logger("MainApp")

async def main():
    # 1. åˆå§‹åŒ–æ¨¡å‹
    ModelFactory.init_models()

    # 2. åˆå§‹åŒ–å·¥å…·
    logger.info("åˆå§‹åŒ–å·¥å…·ç®±...")
    knowledge_base = FinancialKnowledgeBase()
    market_tool = MarketDataManager().get_tool()
    quant_tool = QuantAnalyzer().get_tool()
    
    all_tools = [tool for tool in [market_tool, quant_tool] if tool]

    # 3. æ„å»º Agent
    agent = ReActAgent(
        tools=all_tools,
        llm=Settings.llm,
        verbose=True,
        system_prompt=AGENT_SYSTEM_PROMPT,
        context=AGENT_CONTEXT_INJECTION,
        memory=ChatMemoryBuffer.from_defaults(token_limit=4096)
    )

    conversation_history = []

    def build_agent_input(user_query: str, rag_context: str) -> str:
        sections = []
        if conversation_history:
            recent_history = conversation_history[-3:]
            formatted_history = "\n".join(
                f"ğŸ‘¤ç”¨æˆ·: {turn['user']}\nğŸ¤–é¡¾é—®: {turn['assistant']}" for turn in recent_history
            )
            sections.append("ã€å†å²å¯¹è¯ã€‘\n" + formatted_history)
        if rag_context:
            sections.append("ã€financial_theory_tool æ£€ç´¢æ‘˜è¦ã€‘\n" + rag_context)
        sections.append("ã€å½“å‰ç”¨æˆ·é—®é¢˜ã€‘\n" + user_query)
        sections.append("è¯·å…ˆä¾æ®ç†è®ºæ‘˜è¦å»ºç«‹å³æ—¶è§‚ç‚¹ï¼Œå†è§†éœ€è¦è°ƒç”¨ market_data_tool æˆ– quant_analysis_toolï¼Œæœ€åä»¥ä¸“ä¸šä½†æ˜“æ‡‚çš„æŠ•èµ„é¡¾é—®å£å»è¾“å‡ºç»“è®ºã€‚")
        return "\n\n".join(sections)

    # 4. äº¤äº’å¾ªç¯
    print("\nğŸ¤– é‡åŒ–æŠ•èµ„é¡¾é—®å·²å°±ç»ª (è¾“å…¥ 'exit' é€€å‡º)")
    while True:
        user_input = input("\nğŸ‘¤ ç”¨æˆ·: ")
        if user_input.lower() in ["exit", "quit"]:
            break
        
        try:
            rag_context = knowledge_base.query_raw(user_input)

            enriched_input = build_agent_input(user_input, rag_context)
            response = await agent.run(enriched_input)
            conversation_history.append({"user": user_input, "assistant": str(response)})
            if len(conversation_history) > 5:
                conversation_history.pop(0)
            print(f"\nğŸ¤– é¡¾é—®: {response}")
        except Exception as e:
            logger.error(f"è¿è¡Œå‡ºé”™: {e}")

if __name__ == "__main__":
    asyncio.run(main())