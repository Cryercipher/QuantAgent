{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a1689c-1948-4043-87c2-ca353205288f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å½“å‰å·²åˆ†é…æ˜¾å­˜: 15.08 GB\n",
      "å½“å‰ç¼“å­˜ä¸­æ˜¾å­˜: 15.36 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# æŸ¥çœ‹é‡Šæ”¾åçš„æ˜¾å­˜çŠ¶æ€\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"å½“å‰å·²åˆ†é…æ˜¾å­˜: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"å½“å‰ç¼“å­˜ä¸­æ˜¾å­˜: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"No GPU \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d70d46b-cbef-4119-9bb3-1dd7f9687876",
   "metadata": {},
   "source": [
    "`ssh -p 20078 -L 6006:127.0.0.1:6006 root@cn-east-ai-1.yovole.com`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "548df1b8-39f7-4ca7-ac11-bfe63d78c31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Existing running Phoenix instance detected! Shutting it down and starting a new instance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â—ï¸ The launch_app `port` parameter is deprecated and will be removed in a future release. Use the `PHOENIX_PORT` environment variable instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to instrument while already instrumented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "ğŸ“– For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n",
      "æ­£åœ¨åŠ è½½ Embedding æ¨¡å‹...\n",
      "Embedding æ¨¡å‹åŠ è½½å®Œæˆã€‚\n",
      "æ­£åœ¨åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6eac618bf14888942d444503f46abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "import phoenix as px\n",
    "from llama_index.core import set_global_handler\n",
    "\n",
    "# å¯åŠ¨æœ¬åœ°å¯è§†åŒ–æœåŠ¡å™¨\n",
    "session = px.launch_app(port=6006)\n",
    "\n",
    "# è®¾ç½®å…¨å±€å¤„ç†ç¨‹åº\n",
    "set_global_handler(\"arize_phoenix\")\n",
    "\n",
    "print(\"æ­£åœ¨åŠ è½½ Embedding æ¨¡å‹...\")\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"/root/nas-private/huggingface_cache/BAAI/bge-small-zh-v1.5\"\n",
    ")\n",
    "# åº”ç”¨åˆ°å…¨å±€è®¾ç½®\n",
    "Settings.embed_model = embed_model\n",
    "print(\"Embedding æ¨¡å‹åŠ è½½å®Œæˆã€‚\")\n",
    "\n",
    "HF_CACHE_DIR = \"/root/nas-private/huggingface_cache\"\n",
    "LLM_RELATIVE_PATH = \"Qwen/Qwen3-4B-instruct\" \n",
    "LOCAL_LLM_PATH = os.path.join(HF_CACHE_DIR, LLM_RELATIVE_PATH)\n",
    "model_name = LOCAL_LLM_PATH\n",
    "\n",
    "# Instruct æ¨¡å‹å¿…é¡»ç”¨è¿™ç§æ ¼å¼åŒ…è£¹ï¼Œå¦åˆ™å®ƒä¼šæŠŠå®ƒå½“æˆç»­å†™å°è¯´\n",
    "def qwen_completion_to_prompt(completion):\n",
    "    return (\n",
    "        f\"<|im_start|>system\\n\"\n",
    "        f\"ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ã€‚è¯·æ ¹æ®æä¾›çš„å†…å®¹å›ç­”é—®é¢˜ã€‚\\n\"\n",
    "        f\"<|im_end|>\\n\"\n",
    "        f\"<|im_start|>user\\n\"\n",
    "        f\"{completion}\\n\"\n",
    "        f\"<|im_end|>\\n\"\n",
    "        f\"<|im_start|>assistant\\n\"\n",
    "    )\n",
    "\n",
    "def qwen_messages_to_prompt(messages):\n",
    "    prompt = \"\"\n",
    "    for message in messages:\n",
    "        role = message.role\n",
    "        content = message.content\n",
    "        prompt += f\"<|im_start|>{role}\\n{content}\\n<|im_end|>\\n\"\n",
    "    prompt += \"<|im_start|>assistant\\n\"\n",
    "    return prompt\n",
    "\n",
    "print(\"æ­£åœ¨åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨...\")\n",
    "\n",
    "# åŠ è½½ tokenizer ä»¥ä¾¿è·å– eos_token_id\n",
    "tokenizer = AutoTokenizer.from_pretrained(LOCAL_LLM_PATH, trust_remote_code=True)\n",
    "\n",
    "llm = HuggingFaceLLM(\n",
    "    model_name=LOCAL_LLM_PATH,\n",
    "    tokenizer=tokenizer,\n",
    "    context_window=8192,\n",
    "    max_new_tokens=512,\n",
    "    \n",
    "    # å…³é”®ç‚¹ A: å‘Šè¯‰ LlamaIndex æ€ä¹ˆæŠŠæ–‡æœ¬è½¬æ¢æˆ Qwen çš„èŠå¤©æ ¼å¼\n",
    "    completion_to_prompt=qwen_completion_to_prompt,\n",
    "    messages_to_prompt=qwen_messages_to_prompt,\n",
    "    \n",
    "    # å…³é”®ç‚¹ B: ç”Ÿæˆå‚æ•°æ§åˆ¶\n",
    "    generate_kwargs={\n",
    "        \"temperature\": 0.1,         # RAG ä»»åŠ¡å»ºè®®ä½æ¸©åº¦ï¼Œå‡å°‘èƒ¡è¨€ä¹±è¯­\n",
    "        \"do_sample\": True,\n",
    "        \"repetition_penalty\": 1.1,  # ã€é‡è¦ã€‘æƒ©ç½šé‡å¤å†…å®¹ï¼Œè®¾ä¸º 1.1 æˆ– 1.2\n",
    "        # ã€é‡è¦ã€‘Qwen çš„ç‰¹æ®Šåœæ­¢ç¬¦ï¼Œé˜²æ­¢å®ƒåœä¸ä¸‹æ¥\n",
    "        # 151645 æ˜¯ <|im_end|>, 151643 æ˜¯ <|endoftext|>\n",
    "        \"eos_token_id\": [151645, 151643, tokenizer.eos_token_id], \n",
    "    },\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de581bb1-7f2e-46cc-889c-da69a9da52ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [Cache Hit] è‚¡ç¥¨åˆ—è¡¨å‘½ä¸­æœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€è¯·æ±‚ API\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>area</th>\n",
       "      <th>industry</th>\n",
       "      <th>list_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>000001</td>\n",
       "      <td>å¹³å®‰é“¶è¡Œ</td>\n",
       "      <td>æ·±åœ³</td>\n",
       "      <td>é“¶è¡Œ</td>\n",
       "      <td>19910403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.SZ</td>\n",
       "      <td>000002</td>\n",
       "      <td>ä¸‡ç§‘A</td>\n",
       "      <td>æ·±åœ³</td>\n",
       "      <td>å…¨å›½åœ°äº§</td>\n",
       "      <td>19910129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000004.SZ</td>\n",
       "      <td>000004</td>\n",
       "      <td>*STå›½å</td>\n",
       "      <td>æ·±åœ³</td>\n",
       "      <td>è½¯ä»¶æœåŠ¡</td>\n",
       "      <td>19910114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000006.SZ</td>\n",
       "      <td>000006</td>\n",
       "      <td>æ·±æŒ¯ä¸šA</td>\n",
       "      <td>æ·±åœ³</td>\n",
       "      <td>åŒºåŸŸåœ°äº§</td>\n",
       "      <td>19920427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000007.SZ</td>\n",
       "      <td>000007</td>\n",
       "      <td>å…¨æ–°å¥½</td>\n",
       "      <td>æ·±åœ³</td>\n",
       "      <td>å…¶ä»–å•†ä¸š</td>\n",
       "      <td>19920413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>920981.BJ</td>\n",
       "      <td>920981</td>\n",
       "      <td>æ™¶èµ›ç§‘æŠ€</td>\n",
       "      <td>å®‰å¾½</td>\n",
       "      <td>å…ƒå™¨ä»¶</td>\n",
       "      <td>20211115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5449</th>\n",
       "      <td>920982.BJ</td>\n",
       "      <td>920982</td>\n",
       "      <td>é”¦æ³¢ç”Ÿç‰©</td>\n",
       "      <td>å±±è¥¿</td>\n",
       "      <td>åŒ»ç–—ä¿å¥</td>\n",
       "      <td>20230720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5450</th>\n",
       "      <td>920985.BJ</td>\n",
       "      <td>920985</td>\n",
       "      <td>æµ·æ³°æ–°èƒ½</td>\n",
       "      <td>æ²³åŒ—</td>\n",
       "      <td>ç”µæ°”è®¾å¤‡</td>\n",
       "      <td>20220808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5451</th>\n",
       "      <td>920992.BJ</td>\n",
       "      <td>920992</td>\n",
       "      <td>ä¸­ç§‘ç¾è±</td>\n",
       "      <td>å®‰å¾½</td>\n",
       "      <td>åŒ»ç–—ä¿å¥</td>\n",
       "      <td>20221018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>689009.SH</td>\n",
       "      <td>689009</td>\n",
       "      <td>ä¹å·å…¬å¸-WD</td>\n",
       "      <td>åŒ—äº¬</td>\n",
       "      <td>æ‘©æ‰˜è½¦</td>\n",
       "      <td>20201029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5453 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ts_code  symbol     name area industry  list_date\n",
       "0     000001.SZ  000001     å¹³å®‰é“¶è¡Œ   æ·±åœ³       é“¶è¡Œ   19910403\n",
       "1     000002.SZ  000002      ä¸‡ç§‘A   æ·±åœ³     å…¨å›½åœ°äº§   19910129\n",
       "2     000004.SZ  000004    *STå›½å   æ·±åœ³     è½¯ä»¶æœåŠ¡   19910114\n",
       "3     000006.SZ  000006     æ·±æŒ¯ä¸šA   æ·±åœ³     åŒºåŸŸåœ°äº§   19920427\n",
       "4     000007.SZ  000007      å…¨æ–°å¥½   æ·±åœ³     å…¶ä»–å•†ä¸š   19920413\n",
       "...         ...     ...      ...  ...      ...        ...\n",
       "5448  920981.BJ  920981     æ™¶èµ›ç§‘æŠ€   å®‰å¾½      å…ƒå™¨ä»¶   20211115\n",
       "5449  920982.BJ  920982     é”¦æ³¢ç”Ÿç‰©   å±±è¥¿     åŒ»ç–—ä¿å¥   20230720\n",
       "5450  920985.BJ  920985     æµ·æ³°æ–°èƒ½   æ²³åŒ—     ç”µæ°”è®¾å¤‡   20220808\n",
       "5451  920992.BJ  920992     ä¸­ç§‘ç¾è±   å®‰å¾½     åŒ»ç–—ä¿å¥   20221018\n",
       "5452  689009.SH  689009  ä¹å·å…¬å¸-WD   åŒ—äº¬      æ‘©æ‰˜è½¦   20201029\n",
       "\n",
       "[5453 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tushare as ts\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# åˆå§‹åŒ–\n",
    "ts.set_token('d47f91ee6571a468cd4fae2f7396351260783b2de1370531d3eb5cc0')\n",
    "pro = ts.pro_api()\n",
    "\n",
    "def get_stock_basic_with_cache(cache_path='/root/Desktop/data/stock/stock_basic.csv'):\n",
    "    \"\"\"\n",
    "    è·å–è‚¡ç¥¨åŸºç¡€åˆ—è¡¨ï¼ˆå¸¦ç¼“å­˜æœºåˆ¶ï¼‰ã€‚\n",
    "    é€»è¾‘ï¼šä¼˜å…ˆè¯»æœ¬åœ° CSVï¼Œå¦‚æœæœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸æ˜¯ä»Šå¤©çš„ï¼Œåˆ™è°ƒ Tushare API æ›´æ–°ã€‚\n",
    "    \"\"\"\n",
    "    # 1. ç¡®ä¿ç›®å½•å­˜åœ¨\n",
    "    os.makedirs(os.path.dirname(cache_path), exist_ok=True)\n",
    "    \n",
    "    need_update = True\n",
    "    \n",
    "    # 2. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "    if os.path.exists(cache_path):\n",
    "        # è·å–æ–‡ä»¶æœ€åä¿®æ”¹æ—¶é—´\n",
    "        file_time = os.path.getmtime(cache_path)\n",
    "        file_date = datetime.fromtimestamp(file_time).strftime('%Y%m%d')\n",
    "        today_date = datetime.now().strftime('%Y%m%d')\n",
    "        \n",
    "        # 3. å¦‚æœæ˜¯ä»Šå¤©çš„æ–‡ä»¶ï¼Œå°±ä¸æ›´æ–°\n",
    "        if file_date == today_date:\n",
    "            need_update = False\n",
    "            print(\"âœ… [Cache Hit] è‚¡ç¥¨åˆ—è¡¨å‘½ä¸­æœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€è¯·æ±‚ API\")\n",
    "    \n",
    "    if need_update:\n",
    "        print(\"ğŸ”„ [API Call] æœ¬åœ°åˆ—è¡¨è¿‡æœŸæˆ–ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä» Tushare æ›´æ–°è‚¡ç¥¨åˆ—è¡¨...\")\n",
    "        try:\n",
    "            # è·å–æ‰€æœ‰ä¸Šå¸‚å…¬å¸\n",
    "            df = pro.query('stock_basic', exchange='', list_status='L', fields='ts_code,symbol,name,area,industry,list_date')\n",
    "            # ä¿å­˜åˆ°æœ¬åœ°\n",
    "            df.to_csv(cache_path, index=False)\n",
    "            print(f\"âœ… æ›´æ–°å®Œæˆï¼å·²ä¿å­˜è‡³ {cache_path}ï¼Œå…± {len(df)} æ¡æ•°æ®ã€‚\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ æ›´æ–°å¤±è´¥: {e}\")\n",
    "            # å¦‚æœæ›´æ–°å¤±è´¥ä½†æœ¬åœ°æœ‰æ—§æ–‡ä»¶ï¼Œå°è¯•è¯»å–æ—§æ–‡ä»¶ä½œä¸ºå…œåº•\n",
    "            if os.path.exists(cache_path):\n",
    "                print(\"âš ï¸ æ­£åœ¨é™çº§ä½¿ç”¨æœ¬åœ°æ—§æ•°æ®...\")\n",
    "                return pd.read_csv(cache_path, dtype={'symbol': str})\n",
    "            else:\n",
    "                return pd.DataFrame() # è¿”å›ç©ºè¡¨\n",
    "\n",
    "    # 4. è¯»å–æœ¬åœ°æ–‡ä»¶è¿”å›\n",
    "    # dtype={'symbol': str} å¾ˆé‡è¦ï¼Œé˜²æ­¢è‚¡ç¥¨ä»£ç  '000001' è¢«è¯»æˆæ•°å­— 1\n",
    "    return pd.read_csv(cache_path, dtype={'symbol': str})\n",
    "\n",
    "get_stock_basic_with_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e228ae2-0bad-4fe4-8bbf-f841865709e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ [Tool Call] æ­£åœ¨æŸ¥è¯¢ èŒ…å°...\n",
      "âœ… [Cache Hit] è‚¡ç¥¨åˆ—è¡¨å‘½ä¸­æœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€è¯·æ±‚ API\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ã€è´µå·èŒ…å° (600519.SH) è¡Œæƒ…æ•°æ®ã€‘\\næœ€æ–°æ”¶ç›˜: 1452.0 å…ƒ\\nè¿‘30å¤©å‡ä»·: 1449.70 å…ƒ\\nèµ°åŠ¿: [1476.0, 1471.01, 1467.11, 1466.6, 1452.0]å…¨é‡:       ts_code trade_date     open     high      low    close  pre_close  \\\\\\n20  600519.SH   20251027  1440.00  1452.49  1435.99  1440.41    1450.00   \\n19  600519.SH   20251028  1442.00  1451.20  1441.10  1445.00    1440.41   \\n18  600519.SH   20251029  1440.02  1446.55  1430.04  1431.90    1445.00   \\n17  600519.SH   20251030  1421.81  1436.63  1421.81  1426.74    1431.90   \\n16  600519.SH   20251031  1422.00  1435.98  1420.11  1430.01    1426.74   \\n\\n    change  pct_chg       vol       amount  \\n20   -9.59  -0.6614  37102.39  5352667.152  \\n19    4.59   0.3187  27124.33  3923817.140  \\n18  -13.10  -0.9066  33937.11  4868780.319  \\n17   -5.16  -0.3604  47456.10  6768821.311  \\n16    3.27   0.2292  35693.77  5109623.861  '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_stock_market_data(stock_name: str, days_ago: int = 30) -> str:\n",
    "    \"\"\"\n",
    "    æŸ¥è¯¢è‚¡ç¥¨è¡Œæƒ…ï¼ˆé›†æˆç¼“å­˜ä¼˜åŒ–ï¼‰ã€‚\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ”§ [Tool Call] æ­£åœ¨æŸ¥è¯¢ {stock_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # =======================================================\n",
    "        # 1. è°ƒç”¨ç¼“å­˜å‡½æ•°è·å–ä»£ç è¡¨\n",
    "        # =======================================================\n",
    "        df_basic = get_stock_basic_with_cache() \n",
    "        \n",
    "        if df_basic.empty:\n",
    "            return \"ç³»ç»Ÿé”™è¯¯ï¼šæ— æ³•è·å–è‚¡ç¥¨åŸºç¡€åˆ—è¡¨ã€‚\"\n",
    "\n",
    "        # 2. æ¨¡ç³ŠåŒ¹é…\n",
    "        # åœ¨ name åˆ—ä¸­å¯»æ‰¾åŒ¹é…çš„è¡Œ\n",
    "        matched_row = df_basic[df_basic['name'].str.contains(stock_name)]\n",
    "        \n",
    "        if matched_row.empty:\n",
    "            return f\"é”™è¯¯ï¼šæœªæ‰¾åˆ°åç§°ä¸­åŒ…å« '{stock_name}' çš„è‚¡ç¥¨ã€‚\"\n",
    "        \n",
    "        # å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„ç»“æœ\n",
    "        ts_code = matched_row.iloc[0]['ts_code']\n",
    "        real_name = matched_row.iloc[0]['name']\n",
    "        \n",
    "        # 3. æ—¥çº¿æ•°æ®ä¸éœ€è¦ç¼“å­˜ï¼Œå› ä¸ºç”¨æˆ·å¯èƒ½éšæ—¶æŸ¥\n",
    "        end_date = datetime.now().strftime('%Y%m%d')\n",
    "        start_date = (datetime.now() - timedelta(days=days_ago)).strftime('%Y%m%d')\n",
    "        \n",
    "        df_daily = pro.daily(ts_code=ts_code, start_date=start_date, end_date=end_date)\n",
    "        \n",
    "        if df_daily.empty:\n",
    "            return f\"æœªæŸ¥è¯¢åˆ° {real_name} ({ts_code}) åœ¨æ­¤æœŸé—´çš„æ•°æ®ã€‚\"\n",
    "            \n",
    "        # 4. æ•°æ®æ¸…æ´—ä¸è¿”å›\n",
    "        df_daily = df_daily.sort_values('trade_date', ascending=True)\n",
    "        latest_price = df_daily.iloc[-1]['close']\n",
    "        avg_price = df_daily['close'].mean()\n",
    "        \n",
    "        summary = (\n",
    "            f\"ã€{real_name} ({ts_code}) è¡Œæƒ…æ•°æ®ã€‘\\n\"\n",
    "            f\"æœ€æ–°æ”¶ç›˜: {latest_price} å…ƒ\\n\"\n",
    "            f\"è¿‘{days_ago}å¤©å‡ä»·: {avg_price:.2f} å…ƒ\\n\"\n",
    "            f\"èµ°åŠ¿: {df_daily.tail(5)['close'].tolist()}\"\n",
    "            f\"å…¨é‡: {df_daily.head(5)}\"\n",
    "        )\n",
    "        return summary\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"æŸ¥è¯¢å·¥å…·å‘ç”Ÿé”™è¯¯: {str(e)}\"\n",
    "\n",
    "get_stock_market_data(\"èŒ…å°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4655a542-3142-46bb-8fa4-7373b9f4d85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ [Tool Call] æ­£åœ¨æŸ¥è¯¢ ä¸­å›½äººå¯¿...\n",
      "âœ… [Cache Hit] è‚¡ç¥¨åˆ—è¡¨å‘½ä¸­æœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€è¯·æ±‚ API\n",
      "ğŸ”§ [Tool Call] æ­£åœ¨æŸ¥è¯¢ è´µå·èŒ…å°...\n",
      "âœ… [Cache Hit] è‚¡ç¥¨åˆ—è¡¨å‘½ä¸­æœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€è¯·æ±‚ API\n",
      "è¿‘æœŸæ¥çœ‹ï¼Œä¸­å›½äººå¯¿çš„æœ€æ–°æ”¶ç›˜ä»·ä¸º43.12å…ƒï¼Œè¿‘30å¤©å‡ä»·ä¸º44.01å…ƒï¼Œä»·æ ¼æœ‰æ‰€æ³¢åŠ¨ï¼Œæ•´ä½“å‘ˆç°éœ‡è¡ä¸‹è¡Œè¶‹åŠ¿ã€‚è€Œè´µå·èŒ…å°çš„æœ€æ–°æ”¶ç›˜ä»·ä¸º1452.0å…ƒï¼Œè¿‘30å¤©å‡ä»·ä¸º1449.70å…ƒï¼Œä»·æ ¼ç›¸å¯¹ç¨³å®šï¼Œè™½æœ‰å°å¹…å›è°ƒä½†æ•´ä½“è¡¨ç°ç¨³å¥ã€‚ä»é•¿æœŸæŠ•èµ„è§’åº¦çœ‹ï¼Œè´µå·èŒ…å°ä½œä¸ºæ¶ˆè´¹é¾™å¤´ï¼Œå“ç‰ŒåŠ›å¼ºã€ç›ˆåˆ©èƒ½åŠ›çªå‡ºï¼ŒæŠ—é£é™©èƒ½åŠ›æ›´å¼ºï¼›è€Œä¸­å›½äººå¯¿ä½œä¸ºé‡‘èä¿é™©ç±»ä¼ä¸šï¼Œå—å®è§‚ç»æµå’Œåˆ©ç‡ç¯å¢ƒå½±å“è¾ƒå¤§ã€‚ç»¼åˆè€ƒè™‘ï¼Œå¦‚æœæ›´çœ‹é‡ç¨³å®šæ€§ä¸é˜²å¾¡æ€§ï¼Œè´µå·èŒ…å°å¯èƒ½æ›´é€‚åˆï¼›è‹¥åå¥½æˆé•¿æ€§å’Œè¡Œä¸šç‰¹æ€§ï¼Œä¸­å›½äººå¯¿ä¹Ÿæœ‰å…¶ä»·å€¼ã€‚å»ºè®®æ ¹æ®ä¸ªäººé£é™©æ‰¿å—èƒ½åŠ›å’ŒæŠ•èµ„ç›®æ ‡æ¥é€‰æ‹©ã€‚\n",
      "ğŸ§® [ML Tool] æ­£åœ¨æ‹‰å– è´µå·èŒ…å° çš„å†å²æ•°æ®å¹¶è¿›è¡Œå»ºæ¨¡è®¡ç®—...\n",
      "âœ… [Cache Hit] è‚¡ç¥¨åˆ—è¡¨å‘½ä¸­æœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€è¯·æ±‚ API\n",
      "ğŸ§® [ML Tool] æ­£åœ¨æ‹‰å– è´µå·èŒ…å° çš„å†å²æ•°æ®å¹¶è¿›è¡Œå»ºæ¨¡è®¡ç®—...\n",
      "âœ… [Cache Hit] è‚¡ç¥¨åˆ—è¡¨å‘½ä¸­æœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€è¯·æ±‚ API\n",
      "ğŸ§® [ML Tool] æ­£åœ¨æ‹‰å– è´µå·èŒ…å° çš„å†å²æ•°æ®å¹¶è¿›è¡Œå»ºæ¨¡è®¡ç®—...\n",
      "âœ… [Cache Hit] è‚¡ç¥¨åˆ—è¡¨å‘½ä¸­æœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€è¯·æ±‚ API\n",
      "ğŸ§® [ML Tool] æ­£åœ¨æ‹‰å– è´µå·èŒ…å° çš„å†å²æ•°æ®å¹¶è¿›è¡Œå»ºæ¨¡è®¡ç®—...\n",
      "âœ… [Cache Hit] è‚¡ç¥¨åˆ—è¡¨å‘½ä¸­æœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€è¯·æ±‚ API\n",
      "ğŸ§® [ML Tool] æ­£åœ¨æ‹‰å– è´µå·èŒ…å° çš„å†å²æ•°æ®å¹¶è¿›è¡Œå»ºæ¨¡è®¡ç®—...\n",
      "âœ… [Cache Hit] è‚¡ç¥¨åˆ—è¡¨å‘½ä¸­æœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€è¯·æ±‚ API\n",
      "ğŸ§® [ML Tool] æ­£åœ¨æ‹‰å– è´µå·èŒ…å° çš„å†å²æ•°æ®å¹¶è¿›è¡Œå»ºæ¨¡è®¡ç®—...\n",
      "âœ… [Cache Hit] è‚¡ç¥¨åˆ—è¡¨å‘½ä¸­æœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€è¯·æ±‚ API\n",
      "ğŸ§® [ML Tool] æ­£åœ¨æ‹‰å– è´µå·èŒ…å° çš„å†å²æ•°æ®å¹¶è¿›è¡Œå»ºæ¨¡è®¡ç®—...\n",
      "âœ… [Cache Hit] è‚¡ç¥¨åˆ—è¡¨å‘½ä¸­æœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€è¯·æ±‚ API\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "# 1. å°è£… Tushare å·¥å…·\n",
    "tushare_tool = FunctionTool.from_defaults(\n",
    "    fn=get_stock_market_data,\n",
    "    description=\"ç”¨äºæŸ¥è¯¢ä¸­å›½Aè‚¡è‚¡ç¥¨çš„å®æ—¶/å†å²è¡Œæƒ…æ•°æ®ã€‚è¾“å…¥è‚¡ç¥¨ä¸­æ–‡åå³å¯ï¼ˆå¦‚'æ‹›å•†é“¶è¡Œ'ï¼‰ï¼Œæ— éœ€ä»£ç ã€‚\"\n",
    ")\n",
    "\n",
    "tools = [tushare_tool] \n",
    "agent = agent = ReActAgent(tools=tools, llm=Settings.llm, verbose=True)\n",
    "response = await agent.run(\"ä¸­å›½äººå¯¿æœ€è¿‘èµ°åŠ¿æ€ä¹ˆæ ·ï¼Ÿè´µå·èŒ…å°å‘¢ï¼Ÿä½ è§‰å¾—è¿™ä¸¤æ”¯è‚¡ç¥¨å“ªä¸ªå¥½ä¸€ç‚¹ï¼Ÿ\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ace36d-dc17-439b-a5f0-8a47bd4f4e8f",
   "metadata": {},
   "source": [
    "<img src=\"imgs/deepseek_mermaid_20251123_6e97d7.png\" width=\"800\" height=\"800\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1fa3d87-a9d2-4505-b368-852efd2fa361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ åˆå§‹åŒ– RAG å¼•æ“ | æ•°æ®åº“è·¯å¾„: /root/Desktop/chroma_db\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcc43b6866c4ffa8a44328670b6347a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5295dcc3284e35836f213d9fc2ce33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç´¢å¼•æ„å»ºå®Œæˆå¹¶å·²æŒä¹…åŒ–ä¿å­˜ï¼\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader, \n",
    "    VectorStoreIndex, \n",
    "    StorageContext, \n",
    "    Settings\n",
    ")\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "# ==========================================\n",
    "# é…ç½®éƒ¨åˆ†\n",
    "# ==========================================\n",
    "DATA_DIR = \"/root/Desktop/data/text\"           # åŸå§‹ txt æ–‡ä»¶å­˜æ”¾è·¯å¾„\n",
    "PERSIST_DIR = \"/root/Desktop/chroma_db\"         # å‘é‡æ•°æ®åº“è½ç›˜è·¯å¾„\n",
    "COLLECTION_NAME = \"finance_rules\"   # æ•°æ®åº“ä¸­çš„è¡¨å\n",
    "\n",
    "\n",
    "def get_rag_tool():\n",
    "    print(f\"ğŸš€ åˆå§‹åŒ– RAG å¼•æ“ | æ•°æ®åº“è·¯å¾„: {PERSIST_DIR}\")\n",
    "\n",
    "    # 1. åˆå§‹åŒ– Chroma å®¢æˆ·ç«¯ (æŒä¹…åŒ–æ¨¡å¼)\n",
    "    db = chromadb.PersistentClient(path=PERSIST_DIR)\n",
    "    \n",
    "    # 2. è·å–æˆ–åˆ›å»ºé›†åˆ (Collection)\n",
    "    chroma_collection = db.get_or_create_collection(COLLECTION_NAME)\n",
    "    \n",
    "    # 3. å®šä¹‰ LlamaIndex çš„å‘é‡å­˜å‚¨æ¥å£\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "    # 4. åˆ¤æ–­é€»è¾‘ï¼šæ˜¯â€œåŠ è½½æ—§æ•°æ®â€è¿˜æ˜¯â€œæ–°å»ºç´¢å¼•â€ï¼Ÿ\n",
    "    doc_count = chroma_collection.count()\n",
    "        \n",
    "    # 4.1 è¯»å–æ–‡æ¡£\n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        os.makedirs(DATA_DIR)\n",
    "        print(f\"è¯·å°†è§„åˆ™æ–‡ä»¶æ”¾å…¥ {DATA_DIR}\")\n",
    "        return None\n",
    "        \n",
    "    documents = SimpleDirectoryReader(DATA_DIR).load_data()\n",
    "    \n",
    "    transformations = [\n",
    "        SentenceSplitter(chunk_size=512, chunk_overlap=50)\n",
    "    ]\n",
    "    \n",
    "    # 4.3 å»ºç«‹ç´¢å¼•å¹¶è‡ªåŠ¨æŒä¹…åŒ–\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents, \n",
    "        storage_context=storage_context,\n",
    "        transformations=transformations,\n",
    "        show_progress=True\n",
    "    )\n",
    "    print(\"âœ… ç´¢å¼•æ„å»ºå®Œæˆå¹¶å·²æŒä¹…åŒ–ä¿å­˜ï¼\")\n",
    "\n",
    "    # 5. æ„å»ºæŸ¥è¯¢å¼•æ“\n",
    "    rag_query_engine = index.as_query_engine(similarity_top_k=3)\n",
    "\n",
    "    rag_tool = QueryEngineTool(\n",
    "        query_engine=rag_query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"financial_theory_tool\",\n",
    "            description=(\n",
    "                \"è¿™æ˜¯ä¸€ä¸ªé‡åŒ–é‡‘èé¢†åŸŸçš„ç™¾ç§‘å…¨ä¹¦å’Œç†è®ºçŸ¥è¯†åº“ã€‚\"\n",
    "                \"å½“ç”¨æˆ·è¯¢é—®ä»¥ä¸‹å†…å®¹æ—¶ï¼Œå¿…é¡»ä½¿ç”¨æ­¤å·¥å…·ï¼š\"\n",
    "                \"1. é‡‘èåŸºç¡€æ¦‚å¿µçš„å®šä¹‰ï¼ˆå¦‚ï¼šä»€ä¹ˆæ˜¯æµåŠ¨æ€§ã€æ³¢åŠ¨ç‡ã€Alpha/Betaã€æœ€å¤§å›æ’¤ï¼‰ã€‚\"\n",
    "                \"2. å¸‚åœºå¾®è§‚ç»“æ„å’Œäº¤æ˜“æœºåˆ¶ï¼ˆå¦‚ï¼šè®¢å•ç°¿ã€åšå¸‚å•†ã€äº¤æ˜“æˆæœ¬ã€ç¨è´¹ï¼‰ã€‚\"\n",
    "                \"3. é‡åŒ–ç­–ç•¥çš„ç†è®ºé€»è¾‘ï¼ˆå¦‚ï¼šå¯¹å†²ç­–ç•¥ã€å¥—åˆ©åŸç†ã€å¤šå› å­æ¨¡å‹ï¼‰ã€‚\"\n",
    "                \"4. é‡åŒ–ç³»ç»Ÿçš„è®¡ç®—æœºå·¥ç¨‹åŸºç¡€ï¼ˆå¦‚ï¼šç³»ç»Ÿæ¶æ„è®¾è®¡ã€æ•°æ®åº“é€‰æ‹©ã€å¹¶å‘ç¼–ç¨‹ã€ä½å»¶è¿ŸæŠ€æœ¯ï¼‰ã€‚\"\n",
    "                \"5. æ•°å­¦ä¸ç»Ÿè®¡å­¦åœ¨é‡‘èä¸­çš„åº”ç”¨åŸç†ã€‚\"\n",
    "                \"æ³¨æ„ï¼šæ­¤å·¥å…·ä¸æä¾›å®æ—¶è‚¡ä»·ï¼Œä¹Ÿä¸æä¾›å…·ä½“çš„ K çº¿å½¢æ€åˆ†æï¼Œåªæä¾›ç†è®ºæ”¯æŒå’ŒçŸ¥è¯†ç§‘æ™®ã€‚\"\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    return rag_tool\n",
    "\n",
    "rag_tool = get_rag_tool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f32ffc2-bc6f-4e72-8532-ae95e350a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tushare as ts\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from arch import arch_model\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def get_real_market_data(stock_name: str, lookback_days: int = 365) -> pd.DataFrame:\n",
    "    \"\"\"å†…éƒ¨è¾…åŠ©å‡½æ•°ï¼šè·å–æ¸…æ´—åçš„å†å²æ•°æ®ï¼ˆç”¨äºè®­ç»ƒæ¨¡å‹ï¼‰\"\"\"\n",
    "    # 1. è·å–ä»£ç  (å¤ç”¨ä¹‹å‰çš„ç¼“å­˜é€»è¾‘)\n",
    "    try:\n",
    "        df_basic = get_stock_basic_with_cache() \n",
    "        matched = df_basic[df_basic['name'].str.contains(stock_name)]\n",
    "        if matched.empty:\n",
    "            raise ValueError(f\"æœªæ‰¾åˆ°è‚¡ç¥¨ï¼š{stock_name}\")\n",
    "        ts_code = matched.iloc[0]['ts_code']\n",
    "        name = matched.iloc[0]['name']\n",
    "    except Exception:\n",
    "        # å…œåº•ï¼šå¦‚æœç¼“å­˜å‡½æ•°æ²¡å®šä¹‰ï¼Œå°è¯•ç›´æ¥æŸ¥\n",
    "        df_basic = pro.stock_basic(exchange='', list_status='L', fields='ts_code,name')\n",
    "        matched = df_basic[df_basic['name'].str.contains(stock_name)]\n",
    "        if matched.empty: return None, None\n",
    "        ts_code = matched.iloc[0]['ts_code']\n",
    "        name = matched.iloc[0]['name']\n",
    "\n",
    "    # 2. è·å–å†å²æ—¥çº¿æ•°æ®\n",
    "    end_dt = datetime.now()\n",
    "    start_dt = end_dt - timedelta(days=lookback_days)\n",
    "    \n",
    "    df = pro.daily(ts_code=ts_code, \n",
    "                   start_date=start_dt.strftime('%Y%m%d'), \n",
    "                   end_date=end_dt.strftime('%Y%m%d'))\n",
    "    \n",
    "    if df.empty: return None, None\n",
    "\n",
    "    # 3. æ•°æ®é¢„å¤„ç† (æŒ‰æ—¶é—´æ­£åºæ’åˆ—)\n",
    "    df = df.sort_values('trade_date').reset_index(drop=True)\n",
    "    df['trade_date'] = pd.to_datetime(df['trade_date'])\n",
    "    \n",
    "    # è®¡ç®—å¯¹æ•°æ”¶ç›Šç‡ (Log Return) -é‡‘èå»ºæ¨¡çš„æ ‡å‡†åšæ³•\n",
    "    df['close'] = df['close'].astype(float)\n",
    "    df['log_ret'] = np.log(df['close'] / df['close'].shift(1))\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df, name\n",
    "\n",
    "def analyze_asset_risk(stock_name: str) -> str:\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ Ridge å›å½’å’Œ GARCH æ¨¡å‹è¿›è¡ŒçœŸå®çš„é‡åŒ–åˆ†æã€‚\n",
    "    åŠŸèƒ½ï¼š\n",
    "    1. é¢„æµ‹æœªæ¥çŸ­æœŸæ”¶ç›Šè¶‹åŠ¿ã€‚\n",
    "    2. è®¡ç®—å½“å‰æ³¢åŠ¨ç‡é£é™©ã€‚\n",
    "    3. è®¡ç®— 95% VaR (åœ¨é™©ä»·å€¼)ã€‚\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ§® [ML Tool] æ­£åœ¨æ‹‰å– {stock_name} çš„å†å²æ•°æ®å¹¶è¿›è¡Œå»ºæ¨¡è®¡ç®—...\")\n",
    "    \n",
    "    # 1. è·å–æ•°æ®\n",
    "    try:\n",
    "        data, real_name = get_real_market_data(stock_name)\n",
    "        if data is None or len(data) < 60:\n",
    "            return f\"æ•°æ®ä¸è¶³ï¼Œæ— æ³•å¯¹ {stock_name} è¿›è¡Œæœ‰æ•ˆå»ºæ¨¡ (è‡³å°‘éœ€è¦60ä¸ªäº¤æ˜“æ—¥)ã€‚\"\n",
    "    except Exception as e:\n",
    "        return f\"æ•°æ®è·å–å¤±è´¥: {str(e)}\"\n",
    "\n",
    "    # ======================================================\n",
    "    # æ¨¡å‹ 1: Ridge å›å½’é¢„æµ‹æ”¶ç›Š (Return Prediction)\n",
    "    # ======================================================\n",
    "    # ç‰¹å¾å·¥ç¨‹ï¼šæ„é€ æ»åé¡¹ (Lags) ä½œä¸ºç‰¹å¾\n",
    "    # é€»è¾‘ï¼šç”¨è¿‡å» 5 å¤©çš„æ”¶ç›Šç‡æ¥é¢„æµ‹ä¸‹ä¸€å¤©\n",
    "    lags = 5\n",
    "    for i in range(1, lags + 1):\n",
    "        data[f'lag_{i}'] = data['log_ret'].shift(i)\n",
    "    \n",
    "    data_model = data.dropna()\n",
    "    \n",
    "    # å‡†å¤‡ X (ç‰¹å¾) å’Œ y (ç›®æ ‡)\n",
    "    X = data_model[[f'lag_{i}' for i in range(1, lags + 1)]]\n",
    "    y = data_model['log_ret']\n",
    "    \n",
    "    # ä½¿ç”¨ Pipeline è‡ªåŠ¨åšæ ‡å‡†åŒ– + Ridge å›å½’\n",
    "    # alpha=1.0 æ˜¯æ­£åˆ™åŒ–åŠ›åº¦ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "    model_ridge = make_pipeline(StandardScaler(), Ridge(alpha=1.0))\n",
    "    model_ridge.fit(X, y)\n",
    "    \n",
    "    # é¢„æµ‹ä¸‹ä¸€å¤© (ä½¿ç”¨æœ€åä¸€è¡Œæ•°æ®çš„ç‰¹å¾)\n",
    "    last_features = X.iloc[[-1]]\n",
    "    pred_log_ret = model_ridge.predict(last_features)[0]\n",
    "    \n",
    "    # è½¬åŒ–ä¸ºå¹´åŒ–æ”¶ç›Šç‡ (å‡è®¾ä¸€å¹´250ä¸ªäº¤æ˜“æ—¥)\n",
    "    pred_annual_ret = (np.exp(pred_log_ret * 250) - 1) * 100\n",
    "\n",
    "    # ======================================================\n",
    "    # æ¨¡å‹ 2: GARCH(1,1) æ³¢åŠ¨ç‡å»ºæ¨¡ (Volatility Modeling)\n",
    "    # ======================================================\n",
    "    # é€»è¾‘ï¼šé‡‘èæ•°æ®çš„æ³¢åŠ¨æ˜¯èšé›†çš„ï¼ŒGARCH æ˜¯æ•æ‰è¿™ç§ç‰¹æ€§çš„ SOTA æ¨¡å‹\n",
    "    # æ”¾å¤§ 100 å€æ˜¯ä¸ºäº†æ•°å€¼ç¨³å®šæ€§\n",
    "    returns_scaled = data['log_ret'] * 100 \n",
    "    \n",
    "    # å»ºç«‹ GARCH(1,1) æ¨¡å‹\n",
    "    am = arch_model(returns_scaled, vol='Garch', p=1, o=0, q=1, dist='Normal')\n",
    "    res = am.fit(disp='off', update_freq=0) # disp='off' ä¸æ‰“å°ä¸­é—´è¿‡ç¨‹\n",
    "    \n",
    "    # é¢„æµ‹ä¸‹ä¸€æœŸçš„æ–¹å·®\n",
    "    forecasts = res.forecast(horizon=1)\n",
    "    next_vol_scaled = np.sqrt(forecasts.variance.iloc[-1, 0])\n",
    "    \n",
    "    # è¿˜åŸå¹¶å¹´åŒ–æ³¢åŠ¨ç‡\n",
    "    daily_vol = next_vol_scaled / 100\n",
    "    annual_vol = daily_vol * np.sqrt(250) * 100\n",
    "\n",
    "    # ======================================================\n",
    "    # é£é™©æŒ‡æ ‡: VaR (Value at Risk)\n",
    "    # ======================================================\n",
    "    # è®¡ç®— 95% ç½®ä¿¡åº¦ä¸‹çš„å•æ—¥æœ€å¤§å¯èƒ½äºæŸ\n",
    "    # 1.65 æ˜¯æ­£æ€åˆ†å¸ƒ 95% çš„åˆ†ä½æ•°\n",
    "    var_95 = 1.65 * daily_vol * 100\n",
    "\n",
    "    # ======================================================\n",
    "    # ç”Ÿæˆä¸“ä¸šæŠ¥å‘Š\n",
    "    # ======================================================\n",
    "    \n",
    "    # é£é™©å®šæ€§\n",
    "    if annual_vol < 15: risk_tag = \"ä½æ³¢åŠ¨ (ç¨³å¥)\"\n",
    "    elif annual_vol < 30: risk_tag = \"ä¸­æ³¢åŠ¨ (æ­£å¸¸)\"\n",
    "    else: risk_tag = \"é«˜æ³¢åŠ¨ (é«˜é£é™©)\"\n",
    "\n",
    "    trend = \"çœ‹æ¶¨ ğŸ“ˆ\" if pred_annual_ret > 0 else \"çœ‹è·Œ ğŸ“‰\"\n",
    "    \n",
    "    report = (\n",
    "        f\"ã€{real_name} æ·±åº¦é‡åŒ–åˆ†ææŠ¥å‘Š (åŸºäºè¿‘ä¸€å¹´æ•°æ®)ã€‘\\n\"\n",
    "        f\"----------------------------------------\\n\"\n",
    "        f\"1. æ”¶ç›Šé¢„æµ‹ (æ¨¡å‹: Ridge Regression)\\n\"\n",
    "        f\"   - é¢„æµ‹è¶‹åŠ¿: {trend}\\n\"\n",
    "        f\"   - é¢„æœŸå¹´åŒ–æ”¶ç›Š: {pred_annual_ret:.2f}%\\n\"\n",
    "        f\"   *æ³¨: åŸºäºè¿‡å»5æ—¥åŠ¨é‡å› å­çš„çº¿æ€§å›å½’é¢„æµ‹ã€‚\\n\\n\"\n",
    "        \n",
    "        f\"2. é£é™©è¯„ä¼° (æ¨¡å‹: GARCH(1,1))\\n\"\n",
    "        f\"   - å½“å‰å¹´åŒ–æ³¢åŠ¨ç‡: {annual_vol:.2f}%\\n\"\n",
    "        f\"   - é£é™©ç­‰çº§: {risk_tag}\\n\"\n",
    "        f\"   - 95% VaR (æ—¥): {var_95:.2f}%\\n\"\n",
    "        f\"     (å«ä¹‰: æ˜å¤©æœ‰95%çš„æ¦‚ç‡ï¼Œè·Œå¹…ä¸ä¼šè¶…è¿‡ {var_95:.2f}%)\\n\\n\"\n",
    "        \n",
    "        f\"3. ç»¼åˆå»ºè®®\\n\"\n",
    "        f\"   å½“å‰å¸‚åœºæƒ…ç»ª{'è´ªå©ª' if pred_annual_ret > 20 else 'è°¨æ…'}ï¼Œ\"\n",
    "        f\"æ³¢åŠ¨ç‡å¤„äº{'é«˜ä½' if annual_vol > 30 else 'åˆç†åŒºé—´'}ã€‚\\n\"\n",
    "        f\"   {'å»ºè®®è®¾ç½®ä¸¥æ ¼æ­¢æŸçº¿æˆ–è§‚æœ›ã€‚' if annual_vol > 30 else 'é€‚åˆä½œä¸ºé•¿æœŸèµ„äº§é…ç½®çš„ä¸€éƒ¨åˆ†ã€‚'}\"\n",
    "    )\n",
    "    \n",
    "    return report\n",
    "\n",
    "# å°è£…ä¸º Tool\n",
    "ml_tool = FunctionTool.from_defaults(\n",
    "    fn=analyze_asset_risk,\n",
    "    description=(\n",
    "        \"é«˜çº§é‡‘èé‡åŒ–åˆ†æå·¥å…·ã€‚ä»…å½“ç”¨æˆ·è¯¢é—®'é¢„æµ‹'ã€'æœªæ¥èµ°åŠ¿'ã€'é‡åŒ–åˆ†æ'ã€'é£é™©è¯„ä¼°'æˆ–'è¯¥ä¸è¯¥ä¹°'æ—¶è°ƒç”¨ã€‚\"\n",
    "        \"è¾“å…¥å¯ä»¥æ˜¯è‚¡ç¥¨ä¸­æ–‡åç§°ï¼ˆå¦‚'è´µå·èŒ…å°'ï¼‰ã€‚\"\n",
    "        \"è¯¥å·¥å…·ä¼šè¿è¡Œ Ridge å›å½’å’Œ GARCH æ¨¡å‹è¿›è¡Œå®æ—¶è®¡ç®—ã€‚\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb6acafe-9568-4f0c-b4a8-0d061a1d6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.memory import ChatMemoryBuffer \n",
    "\n",
    "# 1. ç»„è£…å·¥å…·åŒ…\n",
    "all_tools = [tushare_tool, rag_tool, ml_tool]\n",
    "\n",
    "# 2. å®šä¹‰ç³»ç»Ÿæç¤ºè¯\n",
    "system_prompt = \"\"\"\n",
    "ä½ æ˜¯ä¸€åä¸“ä¸šçš„â€œé‡åŒ–é‡‘èæŠ•èµ„é¡¾é—®â€ã€‚ä½ çš„ç›®æ ‡æ˜¯ç»“åˆå®æ—¶æ•°æ®ã€æŠ€æœ¯å½¢æ€å’Œæ·±åšçš„é‡åŒ–ç†è®ºï¼Œä¸ºç”¨æˆ·æä¾›æœ‰ç†æœ‰æ®çš„æŠ•èµ„å»ºè®®ã€‚\n",
    "\n",
    "ä½ çš„å†³ç­–é€»è¾‘å¿…é¡»éµå¾ªâ€œæ•°æ®-å½¢æ€-ç†è®ºâ€çš„ä¸‰ç»´éªŒè¯ä½“ç³»ï¼š\n",
    "\n",
    "1. **å®šé‡åˆ†æï¼ˆæ•°æ®å±‚ï¼‰**ï¼šè°ƒç”¨æ•°æ®å·¥å…·è·å–è‚¡ç¥¨çš„ OHLCVã€å‡çº¿ç­‰å®æ—¶æŒ‡æ ‡ã€‚å¦‚`tushare_tool`åšç®€å•çš„æŸ¥è¯¢ï¼Œ`ml_tool`è¿›è¡Œé«˜é˜¶çš„é‡åŒ–åˆ†æã€‚\n",
    "2. **ç†è®ºæ”¯æ’‘ï¼ˆé€»è¾‘å±‚ï¼‰**ï¼šã€é‡ç‚¹ã€‘å¿…é¡»è°ƒç”¨ `financial_theory_tool` å·¥å…·ï¼Œæ¥è§£é‡Šç°è±¡èƒŒåçš„é‡‘èå­¦åŸç†ã€‚\n",
    "    - ä¾‹å¦‚ï¼šä¸è¦åªè¯´â€œè¿™åªè‚¡ç¥¨æµåŠ¨æ€§ä¸å¥½â€ï¼Œè€Œè¦è§£é‡Šâ€œæ ¹æ®å¸‚åœºå¾®è§‚ç»“æ„ç†è®ºï¼Œè®¢å•ç°¿æ·±åº¦ä¸è¶³ä¼šå¯¼è‡´é«˜æ»‘ç‚¹é£é™©â€ã€‚\n",
    "    - ä¾‹å¦‚ï¼šä¸è¦åªè¯´â€œè¦åˆ†æ•£æŠ•èµ„â€ï¼Œè€Œè¦å¼•ç”¨â€œç°ä»£èµ„äº§ç»„åˆç†è®ºâ€æˆ–â€œé£é™©å¯¹å†²ç­–ç•¥â€æ¥ä½è¯ã€‚\n",
    "    - å¦‚æœç”¨æˆ·è¯¢é—®å¦‚ä½•æ­å»ºé‡åŒ–ç³»ç»Ÿã€æ•°æ®åº“é€‰å‹æˆ– C++/Python æ€§èƒ½ä¼˜åŒ–ï¼Œç›´æ¥æŸ¥è¯¢æ­¤ç†è®ºåº“å›ç­”ã€‚\n",
    "\n",
    "**å›ç­”é£æ ¼è¦æ±‚ï¼š**\n",
    "- ä¸“ä¸šã€ä¸¥è°¨ï¼Œæ‹’ç»æ¨¡æ£±ä¸¤å¯çš„â€œå¯èƒ½â€ã€‚\n",
    "- åœ¨ç»™å‡ºå»ºè®®æ—¶ï¼Œæ˜¾å¼åœ°å¼•ç”¨ç†è®ºä¾æ®ï¼ˆä¾‹å¦‚ï¼šâ€œåŸºäºå‡å€¼å›å½’ç†è®º...â€ï¼‰ã€‚\n",
    "- å¦‚æœç”¨æˆ·æ˜¯å°ç™½ï¼Œç”¨é€šä¿—çš„æ¯”å–»è§£é‡ŠæŸ¥åˆ°çš„ä¸“ä¸šæœ¯è¯­ã€‚\n",
    "\n",
    "**ç¦æ­¢äº‹é¡¹ï¼š**\n",
    "- ä¸¥ç¦åœ¨æ²¡æœ‰æ•°æ®æ”¯æŒçš„æƒ…å†µä¸‹è‡†é€ æŠ•èµ„å»ºè®®ã€‚\n",
    "- ä¸¥ç¦åœ¨è¯¥ç†è®ºçŸ¥è¯†åº“ä¸­æŸ¥è¯¢å…·ä½“çš„å®æ—¶è‚¡ä»·ï¼ˆè¯·ä½¿ç”¨å…¶ä»–å·¥å…·ï¼‰ã€‚\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "281f4bf4-ac72-4697-9796-502719bd3307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== ç¬¬ä¸€è½®ï¼šç«‹äººè®¾ ==========\n",
      "ğŸ§  [Memory] å½“å‰ä¸Šä¸‹æ–‡é•¿åº¦: 0 æ¡æ¶ˆæ¯\n",
      "ğŸ¤– Agent: è´µå·èŒ…å°æœ€è¿‘çš„ç¨³å®šæ€§è¾ƒå¥½ï¼Œå¹´åŒ–æ³¢åŠ¨ç‡ä¸º15.93%ï¼Œå±äºä¸­ç­‰æ³¢åŠ¨æ°´å¹³ï¼Œé£é™©ç­‰çº§ä¸ºâ€œæ­£å¸¸â€ã€‚æ ¹æ®GARCHæ¨¡å‹æµ‹ç®—ï¼Œæ˜å¤©æœ‰95%çš„æ¦‚ç‡è·Œå¹…ä¸è¶…è¿‡1.66%ã€‚åŒæ—¶ï¼ŒåŸºäºRidgeå›å½’æ¨¡å‹çš„æ”¶ç›Šé¢„æµ‹æ˜¾ç¤ºï¼Œæœªæ¥è¶‹åŠ¿çœ‹æ¶¨ï¼Œé¢„æœŸå¹´åŒ–æ”¶ç›Šç‡å¯è¾¾21.78%ã€‚ç»¼åˆæ¥çœ‹ï¼Œå½“å‰å¸‚åœºæƒ…ç»ªåè´ªå©ªï¼Œä½†æ³¢åŠ¨ç‡å¤„äºåˆç†åŒºé—´ï¼Œé€‚åˆä½œä¸ºé•¿æœŸèµ„äº§é…ç½®çš„ä¸€éƒ¨åˆ†ã€‚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "# å¼ºåˆ¶æ³¨å…¥ä¸Šä¸‹æ–‡\n",
    "context = \"\"\"\n",
    "è®°ä½ï¼šä½ ç°åœ¨çš„é¦–è¦ä»»åŠ¡æ˜¯å¿…é¡»è°ƒç”¨ `financial_theory_tool` æ¥å¯»æ‰¾ç†è®ºæ”¯æŒã€‚\n",
    "ä¸è¦ç›´æ¥å›ç­”ï¼Œå…ˆæŸ¥ç†è®ºï¼å…ˆæŸ¥ç†è®ºï¼\n",
    "\"\"\"\n",
    "\n",
    "# åˆå§‹åŒ– Agent (ä¸éœ€è¦åœ¨ init é‡Œä¼  memory äº†ï¼Œå› ä¸ºæˆ‘ä»¬è¦æ‰‹åŠ¨ç®¡)\n",
    "agent = ReActAgent(\n",
    "    tools=all_tools, \n",
    "    llm=Settings.llm, \n",
    "    verbose=True, \n",
    "    context=context,\n",
    "    system_prompt=system_prompt\n",
    ")\n",
    "\n",
    "# åˆå§‹åŒ–è®°å¿†ç¼“å†²åŒº\n",
    "# å®ƒçš„ä½œç”¨æ˜¯ï¼šæ°¸è¿œåªä¿ç•™æœ€è¿‘çš„ 3000 tokenï¼Œè‡ªåŠ¨åˆ æ‰å¤ªä¹…è¿œçš„å¯¹è¯\n",
    "memory_buffer = ChatMemoryBuffer.from_defaults(token_limit=3000)\n",
    "\n",
    "# =================================================================\n",
    "# å®šä¹‰ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼šè´Ÿè´£â€œå¸¦è®°å¿†â€çš„å¯¹è¯\n",
    "# =================================================================\n",
    "async def chat_with_memory(user_input):\n",
    "    # 1. ä»ç¼“å†²åŒºé‡Œå–å‡ºå½“å‰çš„å†å²è®°å½•\n",
    "    # (get() ä¼šè‡ªåŠ¨å¤„ç† token æˆªæ–­ï¼Œä¿è¯ä¸çˆ†æ˜¾å­˜)\n",
    "    current_history = memory_buffer.get()\n",
    "    \n",
    "    print(f\"ğŸ§  [Memory] å½“å‰ä¸Šä¸‹æ–‡é•¿åº¦: {len(current_history)} æ¡æ¶ˆæ¯\")\n",
    "    \n",
    "    # 2. è°ƒç”¨ Agentï¼Œæ˜¾å¼ä¼ å…¥ history\n",
    "    # è¿™ä¸€æ­¥è®© Agent çœ‹åˆ°äº†ä¹‹å‰çš„å¯¹è¯\n",
    "    response = await agent.run(user_msg=user_input, chat_history=current_history)\n",
    "    \n",
    "    # 3. ã€å…³é”®ã€‘æŠŠè¿™ä¸€è½®çš„â€œé—®â€å’Œâ€œç­”â€å­˜å›ç¼“å†²åŒº\n",
    "    # è¿™æ ·ä¸‹ä¸€è½®å°±èƒ½æ‹¿åˆ°äº†\n",
    "    user_msg = ChatMessage(role=MessageRole.USER, content=user_input)\n",
    "    assistant_msg = ChatMessage(role=MessageRole.ASSISTANT, content=str(response))\n",
    "    \n",
    "    memory_buffer.put(user_msg)\n",
    "    memory_buffer.put(assistant_msg)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# =================================================================\n",
    "# å¼€å§‹æµ‹è¯•å¤šè½®å¯¹è¯\n",
    "# =================================================================\n",
    "\n",
    "print(\"\\n========== ç¬¬ä¸€è½®ï¼šç«‹äººè®¾ ==========\")\n",
    "# ç¬¬ä¸€æ¬¡ï¼šå†…å­˜æ˜¯ç©ºçš„\n",
    "res1 = await chat_with_memory(\"è´µå·èŒ…å°æœ€è¿‘çš„ç¨³å®šæ€§ã€æ³¢åŠ¨æ€§æ€ä¹ˆæ ·ï¼Ÿ\")\n",
    "print(f\"ğŸ¤– Agent: {res1}\\n\")\n",
    "\n",
    "# print(\"\\n========== ç¬¬äºŒè½®ï¼šè¿½é—® (æµ‹è¯•è®°å¿†) ==========\")\n",
    "# # ç¬¬äºŒæ¬¡ï¼šå†…å­˜é‡Œå·²ç»æœ‰äº†ä¸Šä¸€è½®çš„å¯¹è¯\n",
    "# # æˆ‘æ•…æ„ä¸æâ€œ50ä¸‡â€å’Œâ€œç¨³å¥å‹â€ï¼Œçœ‹å®ƒèƒ½ä¸èƒ½æ¥ä¸Š\n",
    "# res2 = await chat_with_memory(\"é‚£ç»“åˆæˆ‘çš„æƒ…å†µï¼Œä½ è§‰å¾—ä¹°å¤šå°‘åˆé€‚ï¼Ÿ\")\n",
    "# print(f\"ğŸ¤– Agent: {res2}\\n\")\n",
    "\n",
    "# print(\"\\n========== ç¬¬ä¸‰è½®ï¼šè¿½é—® (æµ‹è¯•è®°å¿†) ==========\")\n",
    "# res3 = await chat_with_memory(\"â€œæˆ‘æ˜¨å¤©å¸‚ä»·ä¹°å…¥äº†ä¸€åªå¾ˆå†·é—¨çš„è‚¡ç¥¨ï¼Œç»“æœæˆäº¤ä»·ç”±äºç°åœ¨çš„ä»·æ ¼å·®å¥½å¤šï¼Œä¸ºä»€ä¹ˆï¼Ÿâ€\")\n",
    "# print(f\"ğŸ¤– Agent: {res3}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1813c80-305a-4ecd-b4e5-870f8a731838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
